# LIMA: Less Is More for Alignment

1. Abst
   1. LIMA は、標準的な教師ありロスで微調整された 65B パラメータの LLaMa 言語モデルで、強化学習や人間の好みのモデリングを行わず、慎重にキュレーションされた 1,000 のプロンプトとレスポンスのみを対象にトレーニングすることにより、これら 2 段階の相対的重要性を測定しました。
   2. LIMA は、旅行計画の立案から代替史の推測に至るまで、複雑なクエリを含むトレーニングデータのほんの一握りの例から、特定の応答フォーマットに従うことを学習し、驚くほど強力な性能を発揮しました。
   3. さらに、このモデルは、訓練データにない未知のタスクにもうまく汎化する傾向があります。
   4. ヒトを対象とした実験では、LIMA の回答が GPT-4 と同等または厳密に優先されるケースが 43％あり、この統計値は Bard と比較すると 58％、ヒトのフィードバックで訓練した DaVinci003 と比較すると 65％という高い数値を示しています。
   5. これらの結果は、大規模言語モデルのほぼ全ての知識は事前学習で学習され、限られたチューニングデータで高品質な出力が得られることを強く示唆しています。
2. Training
   1. アウトプット（回答）は文体が揃っているが、インプット（プロンプト）は多様である。
      1. 具体的には、役に立つ AI アシスタントのようなスタイルのアウトプットを求めています。
      2. 主にコミュニティの Q&A フォーラムと手動で作成された例に分け、様々なソースからそのような例をキュレーションしています。
      3. また、300 のプロンプトからなるテストセットと 50 の開発セットを収集しました。
   2. 各スピーカー（ユーザーとアシスタント）を区別するために、各発話の最後に特別なターン終了トークン（EOT）を導入しています。
      1. このトークンは、EOS と同じ役割を果たすが、学習済みモデルが既存の EOS トークンに付与した他の意味との混同を避けることができる。
   3. 標準的なファインチューニングのハイパーパラメータに従います。
      1. AdamW [Loshchilov and Hutter, 2017]を使用して、β1 = 0.9、β2 = 0.95、重み減衰 0.1 で 15 エポックの微調整を行います。
      2. ウォームアップステップなしで、初期学習率を 1e - 5 に設定し、トレーニングの終了までに 1e - 6 に線形減衰させる。
      3. バッチサイズは 32 例（小さいモデルは 64 例）に設定され、2048 トークンより長いテキストは切り捨てられる。
      4. 標準からの顕著な逸脱は、残留ドロップアウトの使用である。
         1. Ouyang et al. [2022]に従い、残差接続に対するドロップアウトを適用し、最下層で p_d = 0.0 から始め、最後の層で p_d = 0.3 まで直線的に率を上げる（小さいモデルでは p_d = 0.2 ）。
         2. このため、50 例の開発セットを保持したまま、5 番目と 10 番目のエポックの間でチェックポイントを手動で選択することにしました 2。
3. データセット
   1. Stack Exchange
      1. 特徴
         1. Stack Exchange には 179 のオンラインコミュニティ（Exchange）
            1. それぞれが特定のトピックに特化
            2. 最も人気があるのはプログラミング（Stack Overflow）
         2. Stack Exchange はコンテンツの品質に関する高い水準
      2. サンプリング
         1. まず、Exchange を 75 の STEM 交換（プログラミング、数学、物理など）と 99 のその他（英語、料理、旅行など）に分け、5 つのニッチ Exchange を破棄する。
         2. 次に、異なるドメインのより均一なサンプルを得るために、温度 tau= 3 を使用して、各セットから 200 の質問と回答をサンプリングします。
         3. 各 Exchange の中で、タイトルで自己完結している（本文がない）最も高いスコアを持つ質問を取り上げます。
         4. 次に、各質問のトップアンサーを選択し、それが強い正のスコア（少なくとも 10）を持っていたと仮定します。
         5. 親切な AI アシスタントのスタイルに合わせるため、短すぎる回答（1200 文字未満）、長すぎる回答（4096 文字以上）、一人称（「私」「私の」）で書かれた回答、他の回答（「言及されている」「stack exchange」など）を参照している回答を自動的にフィルタリングします。
         6. また、回答からリンク、画像、その他の HTML タグを取り除き、コードブロックとリストのみを保持します。
         7. Stack Exchange の質問にはタイトルと説明文が含まれているため、いくつかの例ではタイトルを、他の例では説明文をランダムに選択します。
   2. wikiHow
      1. 特徴
         1. wikiHow は、様々なトピックに関する 24 万以上のハウツー記事を掲載するオンライン Wiki
         2. wikiHow は誰でも投稿することができますが、記事は厳しく管理されており、その結果、ほぼ普遍的に高品質なコンテンツが提供
      2. サンプリング
         1. wikiHow から 200 の記事を抽出
         2. 多様性を確保するために、まずカテゴリを抽出し（19 のうち）、次にその中の記事を抽出
         3. タイトルをプロンプト（例：「オムレツの作り方」）とし、記事の本文をレスポンスとして使用
         4. 典型的な「この記事は...」で始まるものを「次の答えは...」に置き換え、リンク、画像、テキストの特定の部分を削除するために、多くの前処理ヒューリスティックを適用します。
   3. The Pushshift Reddit Dataset
      1. 特徴
         1. Reddit は世界で最も人気のあるウェブサイトの 1 つで、ユーザーが作成した subreddit のコンテンツを共有、議論、アップヴォートすることができます。
         2. Reddit は、その絶大な人気から、ユーザーを助けるというより、ユーザーを楽しませることに重点を置いています。投稿に対して、真面目で有益なコメントよりも、ウィットで皮肉なコメントの方が多くの票を獲得することがよくあります。
      2. サンプリング
         1. r／AskReddit と r／WritingPrompts の 2 つのサブセットにサンプルを限定し、それぞれのコミュニティで最も投票数の多い投稿から手動で例を選ぶ
         2. r／AskReddit では、70 の自己完結型プロンプト（タイトルのみ、本文なし）が見つかり、上位の回答は必ずしも信頼できないため、これをテストセットに使用
         3. WritingPrompts サブレディットには、架空のストーリーの前提が含まれており、他のユーザーが創造的に完成させることが推奨
         4. 150 のプロンプトと、愛の詩や短い SF 小説などのトピックを含む質の高い回答を見つけ、トレーニングセットに追加しました。
4. Result
   1. 図 1 は人間による嗜好調査の結果、図 2 は GPT-4 による嗜好調査の結果です。GPT-4 もほぼ同じ傾向を示しているため、我々は主に人間実験の結果を調査しています。
   2. Alpaca 65B
      1. 52 倍のデータで学習したにもかかわらず、LIMA よりも好ましくない出力が出る傾向があることがわかりました。この結果は、DaVinci003 が、より優れたアライメント方法であるはずの RLHF でトレーニングされたという事実があるためです。
   3. Bard
      1. DaVinci003 とは逆の傾向で、42%の確率で LIMA より良い反応を示していますが、これは LIMA の 58%の確率で Bard と同等以上の反応を示していることを意味します。
   4. Claude と GPT-4
      1. LIMA よりも一般的に良い結果を出していますが、LIMA が実際に良い結果を出すケースも少なからず存在することがわかります。皮肉なことに、GPT-4 でさえ、19％の確率で LIMA の出力を優先している。
5. 結論
   1. アライメントを目的とした場合、入力の多様性と出力の質を高めると、測定可能なプラスの効果が得られるが、量を高めるだけでは効果が得られない可能性があることがわかった。
   2. 実験セットアップ
      1. 次に、各テストセットのプロンプトに対して 5 つの応答をサンプリングし、ChatGPT（GPT-3.5 Turbo）に応答の有用性を 1 ～ 6 のリッカート尺度で評価させることで応答品質を評価する
   3. 多様性
      1. 優れた回答を持つ異質なプロンプトを持つ Stack Exchange データと、優れた回答を持つ同質なプロンプトを持つ wikiHow データをフィルターにかけた質に対するトレーニングの効果を比較する。
      2. ここでは、多様性の代理として Stack Exchange と wikiHow を比較していますが、2 つの異なるソースからデータをサンプリングする場合、他の混同要因が存在する可能性があることを認めます。各ソースから 2,000 のトレーニング例をサンプリングします（セクション 2.1 と同じプロトコルに従います）。
      3. より多様な Stack Exchange のデータから、著しく高いパフォーマンスが得られることを示しています。
   4. 品質
      1. 応答品質の効果を検証するため、Stack Exchange から品質や文体のフィルターをかけずに 2,000 例をサンプリングし、このデータセットで学習したモデルと、フィルターで絞り込んだデータセットで学習したモデルを比較します。
      2. フィルタリングされたデータソースとフィルタリングされていないデータソースで学習したモデルの間に、0.5 ポイントの有意差があることを示しています
   5. 数量
      1. Stack Exchange から指数関数的に増加するトレーニングセットをサンプリングしました。
      2. トレーニングセットを 2 倍に増やしても、応答の品質は向上しないことがわかります。
      3. アライメントのスケーリング法則が必ずしも量だけに左右されるのではなく、高品質のレスポンスを維持しながら迅速な多様性を実現する関数であることを示唆
6. 課題
   1. たった 1,000 回のシングルターンの対話で微調整されたモデルは、マルチターンの対話に対応できるのだろうか？LIMA の応答は、ゼロショット型チャットボットとしては驚くほど首尾一貫しており、対話の前のステップからの情報を参照しています。10 回の会話のうち 6 回で、LIMA は 3 回の対話の中でプロンプトに従わなかったのです。
   2. 主に、このような例を構築するための精神的な労力は大きく、規模を拡大することは困難です。
   3. LIMA は製品グレードのモデルほど堅牢ではありません。LIMA は通常、優れた応答を生成しますが、デコード中の不運なサンプルや敵対するプロンプトが、しばしば弱い応答につながることがあります。

まとめると

- 多様性が大事
- フィルタリングは必要
  - 極端に長い、極端に短いは省く
  - 一人称が入っている
  - 他を参照している
- 量は大事ではないが、多くて損はない
- LIMA は製品にできるほど堅牢でない
- どちらかというと性能の最大を更新する手法ではなく、少ないデータ・パラメータで性能を引き上げる方法
